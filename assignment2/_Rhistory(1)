beta.ci
#Comparing odds
exp(pfit$coefficients[2])
#CI
vcov(mod.fit)  # Var^(beta^_1) is in the (2,2) element of the matrix
beta.ci < -pfit$coefficients[2] + qnorm(p=c(0.025, 0.975))*sqrt(vcov(mod.fit)[2,2])
beta.ci
rev(exp(beta.ci))  # Reverse order to make it look right
#Comparing odds
exp(pfit$coefficients[2])
#CI
beta.ci<-confint.default(object = mod.fit, parm = "Treatment", level = 0.95)
beta.ci  # C.I. for beta
exp(beta.ci)  # C.I. for OR with c = 1
exp(beta.ci)  # C.I. for OR with c = -10
rev(exp(beta.ci))  # Reverse order to make it look right
#Comparing odds
exp(pfit$coefficients[2])
#CI
beta.ci<-confint.default(object = mod.fit, parm = "TreatmentVaccine", level = 0.95)
beta.ci  # C.I. for beta
exp(beta.ci)  # C.I. for OR with c = 1
exp(beta.ci)  # C.I. for OR with c = -10
rev(exp(beta.ci))  # Reverse order to make it look right
#Comparing odds
exp(pfit$coefficients[2])
#CI
beta.ci<-confint.default(object = pfit, parm = "TreatmentVaccine", level = 0.95)
beta.ci  # C.I. for beta
exp(beta.ci)  # C.I. for OR with c = 1
exp(beta.ci)  # C.I. for OR with c = -10
rev(exp(beta.ci))  # Reverse order to make it look right
#Comparing odds
exp(pfit$coefficients[2])
#CI
beta.ci<-confint.default(object = pfit, parm = "TreatmentVaccine", level = 0.95)
rev(exp(beta.ci))  # Reverse order to make it look right
#Comparing odds
exp(pfit$coefficients[2])
#CI
beta.ci<-confint.default(object = pfit, parm = "TreatmentVaccine", level = 0.95)
exp(beta.ci)  # Reverse order to make it look right
polio
c.table
polio
prop.test(x=c(57, 142), n=c(200745, 201229), alternative="less", correct=FALSE)
prop.test(x=c(57, 142), n=c(200745, 201229), alternative="les", correct=FALSE)
prop.test(x=c(57, 142), n=c(200745, 201229), alternative="le", correct=FALSE)
prop.test(x=c(57, 142), n=c(200745, 201229), alternative="leee", correct=FALSE)
prop.test(x=c(57, 142), n=c(200745, 201229), alternative="greater", correct=FALSE)
prop.test(x=c(57, 142), n=c(200745, 201229), alternative="two-sided", correct=FALSE)
prop.test(x=c(57, 142), n=c(200745, 201229), alternative="two.sided", correct=FALSE)
knitr::opts_chunk$set(echo = TRUE)
library(dplyr)
challenger <- read.csv('U:/stat475/assignment2/challenger.csv')
mod.fit <- glm(formula=O.ring/Number ~ Temp, family=binomial(link = logit), weights = Number, data=challenger)
challenger <- mutate(challenger, proportion = O.ring/Number)
plot(x=challenger$Temp, y=challenger$proportion,
main="Proportions of made challengers with Wilcon CIs",
xlab="Temp", ylab="Proportion of successes")
library(package = binom)
install.packages(c("dplyr", "binom", "PropCIs"))
install.packages(c("dplyr", "binom", "PropCIs"))
install.packages(c("dplyr", "binom", "PropCIs"))
install.packages(c("dplyr", "binom", "PropCIs"))
knitr::opts_chunk$set(echo = TRUE)
library(dplyr)
install.packages(c("dplyr", "binom"))
knitr::opts_chunk$set(echo = TRUE)
library(dplyr)
challenger <- read.csv('U:/stat475/assignment2/challenger.csv')
mod.fit <- glm(formula=O.ring/Number ~ Temp, family=binomial(link = logit), weights = Number, data=challenger)
challenger <- mutate(challenger, proportion = O.ring/Number)
plot(x=challenger$Temp, y=challenger$proportion,
main="Proportions of made challengers with Wilcon CIs",
xlab="Temp", ylab="Proportion of successes")
library(package = binom)
wilson <- function(x){
binom.confint(x = x[4], n = x[5], conf.level = 0.95, methods = "wilson")
}
temp.ci <- apply(X=challenger, MARGIN=1, FUN=wilson)
temp.ci1 <- matrix(data=unlist(temp.ci), byrow = TRUE,  nrow = nrow(challenger))
challenger <- data.frame(challenger, lower=temp.ci1[,5], upper=temp.ci1[,6])
ci.lines <- function(x){segments(x0=x[2], y0=x[7], y1=x[8], col=grey(.7))}
apply(X=challenger, MARGIN=1, FUN=ci.lines)
curve(expr = predict(object = mod.fit, newdata = data.frame(Temp = x), type = "response"), col = "red", add = TRUE,
xlim = c(0, 90))
library(package = mcprofile)
install.packages("mcprofile")
knitr::opts_chunk$set(echo = TRUE)
library(dplyr)
challenger <- read.csv('U:/stat475/assignment2/challenger.csv')
mod.fit <- glm(formula=O.ring/Number ~ Temp, family=binomial(link = logit), weights = Number, data=challenger)
challenger <- mutate(challenger, proportion = O.ring/Number)
plot(x=challenger$Temp, y=challenger$proportion,
main="Proportions of made challengers with Wilcon CIs",
xlab="Temp", ylab="Proportion of successes")
library(package = binom)
wilson <- function(x){
binom.confint(x = x[4], n = x[5], conf.level = 0.95, methods = "wilson")
}
temp.ci <- apply(X=challenger, MARGIN=1, FUN=wilson)
temp.ci1 <- matrix(data=unlist(temp.ci), byrow = TRUE,  nrow = nrow(challenger))
challenger <- data.frame(challenger, lower=temp.ci1[,5], upper=temp.ci1[,6])
ci.lines <- function(x){segments(x0=x[2], y0=x[7], y1=x[8], col=grey(.7))}
apply(X=challenger, MARGIN=1, FUN=ci.lines)
curve(expr = predict(object = mod.fit, newdata = data.frame(Temp = x), type = "response"), col = "red", add = TRUE,
xlim = c(0, 90))
library(package = mcprofile)
# Create the coefficient matrix for the parameters in the
#   linear predictor
K <- as.matrix(cbind(1, challenger$Temp))
class(K)  # matrix
# Use the mcprofile(object=, CM=, ...) function to find profile
#   likelihood values.
# Can take a little time in complex models.
profiles <- mcprofile(object=mod.fit, CM=K)
# There is a confint() method developed specifically for objects
#   produced by mcprofile().  "adjust=" allows you to use methods
#   to control simultaneous coverage probabilities, like Bonferroni
ci.logit.LR <- confint(object=profiles, level=0.95, adjust = "none")
# CI for beta_0 + beta_1 * x
ci.pi.LR <- exp(ci.logit.LR$confint)/(1 + exp(ci.logit.LR$confint))
# Show these as bands on our plot
lines(x = challenger$Temp, y = ci.pi.LR[,1], col = "blue")
lines(x = challenger$Temp, y = ci.pi.LR[,2], col = "blue")
pred <- predict(mod.fit, data.frame(Temp = 31), "response", se.fit = TRUE)
pred
critval <- 1.96 ## approx 95% CI
upr <- pred$fit + (critval * pred$se.fit)
lwr <- pred$fit - (critval * pred$se.fit)
data.frame(lower = lwr, upper = upr)
knitr::opts_chunk$set(echo = TRUE)
library(dplyr)
challenger <- read.csv('U:/stat475/assignment2/challenger.csv')
mod.fit <- glm(formula=O.ring/Number ~ Temp, family=binomial(link = logit), weights = Number, data=challenger)
challenger <- mutate(challenger, proportion = O.ring/Number)
plot(x=challenger$Temp, y=challenger$proportion,
main="Proportions of made challengers with Wilcon CIs",
xlab="Temp", ylab="Proportion of successes")
library(package = binom)
wilson <- function(x){
binom.confint(x = x[4], n = x[5], conf.level = 0.95, methods = "wilson")
}
temp.ci <- apply(X=challenger, MARGIN=1, FUN=wilson)
temp.ci1 <- matrix(data=unlist(temp.ci), byrow = TRUE,  nrow = nrow(challenger))
challenger <- data.frame(challenger, lower=temp.ci1[,5], upper=temp.ci1[,6])
ci.lines <- function(x){segments(x0=x[2], y0=x[7], y1=x[8], col=grey(.7))}
apply(X=challenger, MARGIN=1, FUN=ci.lines)
curve(expr = predict(object = mod.fit, newdata = data.frame(Temp = x), type = "response"), col = "red", add = TRUE,
xlim = c(0, 90))
library(package = mcprofile)
# Create the coefficient matrix for the parameters in the
#   linear predictor
K <- as.matrix(cbind(1, 50:85))
class(K)  # matrix
# Use the mcprofile(object=, CM=, ...) function to find profile
#   likelihood values.
# Can take a little time in complex models.
profiles <- mcprofile(object=mod.fit, CM=K)
# There is a confint() method developed specifically for objects
#   produced by mcprofile().  "adjust=" allows you to use methods
#   to control simultaneous coverage probabilities, like Bonferroni
ci.logit.LR <- confint(object=profiles, level=0.95, adjust = "none")
# CI for beta_0 + beta_1 * x
ci.pi.LR <- exp(ci.logit.LR$confint)/(1 + exp(ci.logit.LR$confint))
# Show these as bands on our plot
lines(x = challenger$Temp, y = ci.pi.LR[,1], col = "blue")
knitr::opts_chunk$set(echo = TRUE)
library(dplyr)
challenger <- read.csv('U:/stat475/assignment2/challenger.csv')
mod.fit <- glm(formula=O.ring/Number ~ Temp, family=binomial(link = logit), weights = Number, data=challenger)
challenger <- mutate(challenger, proportion = O.ring/Number)
plot(x=challenger$Temp, y=challenger$proportion,
main="Proportions of made challengers with Wilcon CIs",
xlab="Temp", ylab="Proportion of successes")
library(package = binom)
wilson <- function(x){
binom.confint(x = x[4], n = x[5], conf.level = 0.95, methods = "wilson")
}
temp.ci <- apply(X=challenger, MARGIN=1, FUN=wilson)
temp.ci1 <- matrix(data=unlist(temp.ci), byrow = TRUE,  nrow = nrow(challenger))
challenger <- data.frame(challenger, lower=temp.ci1[,5], upper=temp.ci1[,6])
ci.lines <- function(x){segments(x0=x[2], y0=x[7], y1=x[8], col=grey(.7))}
apply(X=challenger, MARGIN=1, FUN=ci.lines)
curve(expr = predict(object = mod.fit, newdata = data.frame(Temp = x), type = "response"), col = "red", add = TRUE,
xlim = c(0, 90))
library(package = mcprofile)
# Create the coefficient matrix for the parameters in the
#   linear predictor
K <- as.matrix(cbind(1, 50:85))
class(K)  # matrix
# Use the mcprofile(object=, CM=, ...) function to find profile
#   likelihood values.
# Can take a little time in complex models.
profiles <- mcprofile(object=mod.fit, CM=K)
# There is a confint() method developed specifically for objects
#   produced by mcprofile().  "adjust=" allows you to use methods
#   to control simultaneous coverage probabilities, like Bonferroni
ci.logit.LR <- confint(object=profiles, level=0.95, adjust = "none")
# CI for beta_0 + beta_1 * x
ci.pi.LR <- exp(ci.logit.LR$confint)/(1 + exp(ci.logit.LR$confint))
# Show these as bands on our plot
lines(x = challenger$Temp, y = ci.pi.LR[,1], col = "blue")
# Create the coefficient matrix for the parameters in the
#   linear predictor
K <- as.matrix(cbind(1, c(53:81)))
class(K)  # matrix
# Create the coefficient matrix for the parameters in the
#   linear predictor
K <- as.matrix(cbind(1, c(53:81))
library(dplyr)
library(dplyr)
challenger <- read.csv('U:/stat475/assignment2/challenger.csv')
mod.fit <- glm(formula=O.ring/Number ~ Temp, family=binomial(link = logit), weights = Number, data=challenger)
challenger <- mutate(challenger, proportion = O.ring/Number)
plot(x=challenger$Temp, y=challenger$proportion,
main="Proportions of made challengers with Wilcon CIs",
xlab="Temp", ylab="Proportion of successes")
library(package = binom)
wilson <- function(x){
binom.confint(x = x[4], n = x[5], conf.level = 0.95, methods = "wilson")
}
dist.ci <- apply(X=challenger, MARGIN=1, FUN=wilson)
dist.ci1 <- matrix(data=unlist(dist.ci), byrow = TRUE,  nrow = nrow(challenger))
challenger <- data.frame(challenger, lower=dist.ci1[,5], upper=dist.ci1[,6])
ci.lines <- function(x){segments(x0=x[2], y0=x[7], y1=x[8], col=grey(.7))}
apply(X=challenger, MARGIN=1, FUN=ci.lines)
curve(expr = predict(object = mod.fit, newdata = data.frame(Temp = x), type = "response"), col = "red", add = TRUE,
xlim = c(0, 90))
library(package = mcprofile)
# Create the coefficient matrix for the parameters in the
#   linear predictor
all.temp=c(53:81)
K <- as.matrix(cbind(1,all.temp)
class(K)  # matrix
library(dplyr)
challenger <- read.csv('U:/stat475/assignment2/challenger.csv')
mod.fit <- glm(formula=O.ring/Number ~ Temp, family=binomial(link = logit), weights = Number, data=challenger)
challenger <- mutate(challenger, proportion = O.ring/Number)
plot(x=challenger$Temp, y=challenger$proportion,
main="Proportions of made challengers with Wilcon CIs",
xlab="Temp", ylab="Proportion of successes")
library(package = binom)
wilson <- function(x){
binom.confint(x = x[4], n = x[5], conf.level = 0.95, methods = "wilson")
}
dist.ci <- apply(X=challenger, MARGIN=1, FUN=wilson)
dist.ci1 <- matrix(data=unlist(dist.ci), byrow = TRUE,  nrow = nrow(challenger))
challenger <- data.frame(challenger, lower=dist.ci1[,5], upper=dist.ci1[,6])
ci.lines <- function(x){segments(x0=x[2], y0=x[7], y1=x[8], col=grey(.7))}
apply(X=challenger, MARGIN=1, FUN=ci.lines)
curve(expr = predict(object = mod.fit, newdata = data.frame(Temp = x), type = "response"), col = "red", add = TRUE,
xlim = c(0, 90))
library(package = mcprofile)
# Create the coefficient matrix for the parameters in the
#   linear predictor
all.temp=as.data.frame(Temp=c(53:81))
# Create the coefficient matrix for the parameters in the
#   linear predictor
all.temp=data.frame(Temp=c(53:81))
K <- as.matrix(cbind(1,all.temp))
library(dplyr)
challenger <- read.csv('U:/stat475/assignment2/challenger.csv')
mod.fit <- glm(formula=O.ring/Number ~ Temp, family=binomial(link = logit), weights = Number, data=challenger)
challenger <- mutate(challenger, proportion = O.ring/Number)
plot(x=challenger$Temp, y=challenger$proportion,
main="Proportions of made challengers with Wilcon CIs",
xlab="Temp", ylab="Proportion of successes")
library(package = binom)
wilson <- function(x){
binom.confint(x = x[4], n = x[5], conf.level = 0.95, methods = "wilson")
}
dist.ci <- apply(X=challenger, MARGIN=1, FUN=wilson)
dist.ci1 <- matrix(data=unlist(dist.ci), byrow = TRUE,  nrow = nrow(challenger))
challenger <- data.frame(challenger, lower=dist.ci1[,5], upper=dist.ci1[,6])
ci.lines <- function(x){segments(x0=x[2], y0=x[7], y1=x[8], col=grey(.7))}
apply(X=challenger, MARGIN=1, FUN=ci.lines)
curve(expr = predict(object = mod.fit, newdata = data.frame(Temp = x), type = "response"), col = "red", add = TRUE,
xlim = c(0, 90))
library(package = mcprofile)
# Create the coefficient matrix for the parameters in the
#   linear predictor
all.temp=data.frame(Temp=c(53:81))
K <- as.matrix(cbind(1,all.temp))
class(K)  # matrix
# Use the mcprofile(object=, CM=, ...) function to find profile
#   likelihood values.
# Can take a little time in complex models.
profiles <- mcprofile(object=mod.fit, CM=K)
# There is a confint() method developed specifically for objects
#   produced by mcprofile().  "adjust=" allows you to use methods
#   to control simultaneous coverage probabilities, like Bonferroni
ci.logit.LR <- confint(object=profiles, level=0.95, adjust = "none")
# CI for beta_0 + beta_1 * x
ci.pi.LR <- exp(ci.logit.LR$confint)/(1 + exp(ci.logit.LR$confint))
# Show these as bands on our plot
lines(x = challenger$Temp, y = ci.pi.LR[,1], col = "blue")
library(dplyr)
challenger <- read.csv('U:/stat475/assignment2/challenger.csv')
mod.fit <- glm(formula=O.ring/Number ~ Temp, family=binomial(link = logit), weights = Number, data=challenger)
challenger <- mutate(challenger, proportion = O.ring/Number)
plot(x=challenger$Temp, y=challenger$proportion,
main="Proportions of made challengers with Wilcon CIs",
xlab="Temp", ylab="Proportion of successes")
library(package = binom)
wilson <- function(x){
binom.confint(x = x[4], n = x[5], conf.level = 0.95, methods = "wilson")
}
dist.ci <- apply(X=challenger, MARGIN=1, FUN=wilson)
dist.ci1 <- matrix(data=unlist(dist.ci), byrow = TRUE,  nrow = nrow(challenger))
challenger <- data.frame(challenger, lower=dist.ci1[,5], upper=dist.ci1[,6])
ci.lines <- function(x){segments(x0=x[2], y0=x[7], y1=x[8], col=grey(.7))}
apply(X=challenger, MARGIN=1, FUN=ci.lines)
curve(expr = predict(object = mod.fit, newdata = data.frame(Temp = x), type = "response"), col = "red", add = TRUE,
xlim = c(0, 90))
library(package = mcprofile)
# Create the coefficient matrix for the parameters in the
#   linear predictor
all.temp=data.frame(Temp=c(53:81))
K <- as.matrix(cbind(1,all.temp))
class(K)  # matrix
# Use the mcprofile(object=, CM=, ...) function to find profile
#   likelihood values.
# Can take a little time in complex models.
profiles <- mcprofile(object=mod.fit, CM=K)
# There is a confint() method developed specifically for objects
#   produced by mcprofile().  "adjust=" allows you to use methods
#   to control simultaneous coverage probabilities, like Bonferroni
ci.logit.LR <- confint(object=profiles, level=0.95, adjust = "none")
# CI for beta_0 + beta_1 * x
ci.pi.LR <- exp(ci.logit.LR$confint)/(1 + exp(ci.logit.LR$confint))
# Show these as bands on our plot
lines(x = all.temp[,1], y = ci.pi.LR[,1], col = "blue")
lines(x = all.temp[,1], y = ci.pi.LR[,2], col = "blue")
pred <- predict(mod.fit, data.frame(Temp = 31), "response", se.fit = TRUE)
pred
critval <- 1.96 ## approx 95% CI
upr <- pred$fit + (critval * pred$se.fit)
lwr <- pred$fit - (critval * pred$se.fit)
data.frame(lower = lwr, upper = upr)
knitr::opts_chunk$set(echo = TRUE)
BW <- read.csv(file="U:/stat475/assignment2/placekick.BW.csv", header=TRUE)
library(dplyr)
library(stringr)
BW <- mutate(BW, GameNum = as.factor(GameNum))
cfit <- glm(Good ~ ., family = binomial(link = "logit"), data = BW)
BW %>% filter(Grass == 1, Weather != "Inside") -> Nick
BW %>% filter(Grass == 0, Weather == "Inside") -> Steve
Nick.pred <- predict(cfit, Nick, "response")
Steve.pred <- predict(cfit, Steve, "response")
N <- exp(mean(Nick.pred))/(1+exp(mean(Nick.pred))) ##Nick's mean probability of success
S <- exp(mean(Steve.pred))/(1+exp(mean(Steve.pred))) ##Steve's mean probability of success
data.frame(N, S)
n(Nick[[Good == 1]])
n(Nick[Good == 1])
nrpw(Nick[Good == 1])
nrow(Nick[Good == 1])
nrow(Nick[[Good == 1])
nrow(Nick[[Good == 1]])
nrow(Nick$Good==1)
n(Nick$Good==1)
help('n')
help('nrow')
nrow(Nick %>% filter(Good == 1))
nrow(Nick %>% filter(Good == 0))
nrow(Nick[[Good == "Y"]])
nrow(Nick[Good == "Y"])
nrow(Nick$Good == "Y")
head(Nick)
(Nick %>% filter(Good == "Y"))
nrow(Nick %>% filter(Good == "Y"))
nrow(Nick %>% filter(Good == "N"))
w.v <- nrow(Nick %>% filter(Good == "Y"))
nrow(Nick %>% filter(Good == "N"))
n.v <- nrow(Nick)
w.p <- nrow(Steve %>% filter(Good == "Y"))
nrow(Steve %>% filter(Good == "N"))
n.p <- nrow(Steve)
prop.test(x=c(w.v, w.p), n=c(n.v, n.p), alternative="two.sided", correct=FALSE)
w.v <- nrow(Nick %>% filter(Good == "Y"))
nrow(Nick %>% filter(Good == "N"))
n.v <- nrow(Nick)
w.p <- nrow(Steve %>% filter(Good == "Y"))
nrow(Steve %>% filter(Good == "N"))
n.p <- nrow(Steve)
prop.test(x=c(w.v, w.p), n=c(n.v, n.p), alternative="less", correct=FALSE)
w.v <- nrow(Nick %>% filter(Good == "Y"))
n.v <- nrow(Nick)
w.p <- nrow(Steve %>% filter(Good == "Y"))
n.p <- nrow(Steve)
prop.test(x=c(w.v, w.p), n=c(n.v, n.p), alternative="less", correct=FALSE)
knitr::opts_chunk$set(echo = TRUE)
BW <- read.csv(file="U:/stat475/assignment2/placekick.BW.csv", header=TRUE)
library(dplyr)
library(stringr)
BW <- mutate(BW, GameNum = as.factor(GameNum))
cfit <- glm(Good ~ ., family = binomial(link = "logit"), data = BW)
BW %>% filter(Grass == 1, Weather != "Inside") -> Nick
BW %>% filter(Grass == 0, Weather == "Inside") -> Steve
Nick.pred <- predict(cfit, Nick, "response")
Steve.pred <- predict(cfit, Steve, "response")
N <- exp(mean(Nick.pred))/(1+exp(mean(Nick.pred))) ##Nick's mean probability of success
S <- exp(mean(Steve.pred))/(1+exp(mean(Steve.pred))) ##Steve's mean probability of success
data.frame(N, S)
w.v <- nrow(Nick %>% filter(Good == "Y"))
n.v <- nrow(Nick)
w.p <- nrow(Steve %>% filter(Good == "Y"))
n.p <- nrow(Steve)
prop.test(x=c(w.v, w.p), n=c(n.v, n.p), alternative="less", correct=FALSE)
knitr::opts_chunk$set(echo = TRUE)
placekick <- read.csv("U:/stat475/assignment2/Placekick.csv")
k.fit <- glm(good ~ ., family = binomial(link = logit), data = placekick)
summary(k.fit)
library(car)
k.fit2 <- glm(good ~ distance, family = binomial(link = logit), data = placekick)
anova(k.fit, k.fit2, test = "LR")
Anova(k.fit)
knitr::opts_chunk$set(echo = TRUE)
challenger <- read.csv('U:/stat475/assignment2/challenger.csv')
mod.fit <- glm(formula=O.ring/Number ~ Temp, family=binomial(link = logit), weights = Number, data=challenger)
beta.ci <- confint(object = mod.fit, parm = "Temp", level = 0.95)
beta.ci##LR CI
round(confint.default(mod.fit), digits=3)##Wald CI
knitr::opts_chunk$set(echo = TRUE)
challenger <- read.csv('U:/stat475/assignment2/challenger.csv')
mod.fit <- glm(formula=O.ring/Number ~ Temp, family=binomial(link = logit), weights = Number, data=challenger)
mod.fit
library(dplyr)
challenger <- mutate(challenger, proportion = O.ring/Number)
plot(x=challenger$Temp, y=challenger$proportion,
main="Proportions of made challengers with Wilcon CIs",
xlab="Temp", ylab="Proportion of successes")
head(challenger)
# At each Temp, compute score confidence interval for prob of success
#  Do this by creating a function that computes the score interval on one row
#  and apply the funciton to each row (MARGIN=1) of the challenger data frame.
library(package = binom)
wilson <- function(x){
binom.confint(x = x[4], n = x[5], conf.level = 0.95, methods = "wilson")
}
dist.ci <- apply(X=challenger, MARGIN=1, FUN=wilson)
# Have to do some gymnastics to get out the endpoints.
#  apply() created a list of results, so unlist them into matrix form
#  and add them to our data frame
dist.ci1 <- matrix(data=unlist(dist.ci), byrow = TRUE,  nrow = nrow(challenger))
challenger <- data.frame(challenger, lower=dist.ci1[,5], upper=dist.ci1[,6])
# Now add each line to the plot in the same way.  segments() can draw a line
#   segment on an existing plot from (x0,y0) to (x1,y1).
#   Can omit one x or y if it remains constant, as here we want vertical lines.
ci.lines <- function(x){segments(x0=x[2], y0=x[7], y1=x[8], col=grey(.7))}
apply(X=challenger, MARGIN=1, FUN=ci.lines)
# Add fitted logistic regression curve
# curve() evaluates a function at various points of a generically named variable x.
curve(expr = predict(object = mod.fit, newdata = data.frame(Temp = x), type = "response"), col = "red", add = TRUE,
xlim = c(0, 90))
pred <- function(Temp) {
df <- data.frame(Temp = Temp)
log_odds <- predict(mod.fit, newdata = df)
exp(log_odds)/(exp(log_odds)+1)
}
data.frame(Temp=c(81, 61, 31), probability = c(pred(81), pred(61), pred(31)))
range(challenger$Temp)
pred <- function(Temp) {
df <- data.frame(Temp = Temp)
log_odds <- predict(mod.fit, newdata = df)
log_odds
}
data.frame(Temp=c(81, 61, 31), probability = c(pred(81), pred(61), pred(31)))
pred <- function(Temp) {
df <- data.frame(Temp = Temp)
log_odds <- predict(mod.fit, newdata = df)
exp(log_odds)/(exp(log_odds)+1)
}
data.frame(Temp=c(81, 61, 31), probability = c(pred(81), pred(61), pred(31)))
pred <- function(Temp) {
df <- data.frame(Temp = Temp)
log_odds <- predict(mod.fit, newdata = df, "response")
log_odds
}
data.frame(Temp=c(81, 61, 31), probability = c(pred(81), pred(61), pred(31)))
predict.glm(mod.fit, data.frame(Temp = 31, "response"))
data.frame(Temp=c(81, 61, 31), probability = c(pred(81), pred(61), pred(31)))
predict.glm(mod.fit, data.frame(Temp = 31, "response"))
pred <- function(Temp) {
df <- data.frame(Temp = Temp)
log_odds <- predict(mod.fit, newdata = df)
exp(log_odds)/(exp(log_odds)+1)
}
data.frame(Temp=c(81, 61, 31), probability = c(pred(81), pred(61), pred(31)))
placekick <- as.factor(placekick[.-diatance - elap30]0
placekick <- as.factor(placekick[.-diatance - elap30])
summary(k.fit)
placekick <- read.csv("U:/stat475/assignment2/Placekick.csv")
placekick <- mutate(placekick, week = as.factor(week), change = as.factor(change), PAT = as.factor(PAT), type = as.factor(type), field = as.factor(field), wind = as.factor(wind))
k.fit <- glm(good ~ ., family = binomial(link = logit), data = placekick)
summary(k.fit)
library(car)
k.fit2 <- glm(good ~ distance, family = binomial(link = logit), data = placekick)
anova(k.fit, k.fit2, test = "LR")
placekick <- mutate(placekick, week = as.factor(week), change = as.factor(change), PAT = as.factor(PAT), type = as.factor(type), field = as.factor(field), wind = as.factor(wind))
placekick <- read.csv("U:/stat475/assignment2/Placekick.csv")
placekick <- mutate(placekick, week = as.factor(week), change = as.factor(change), PAT = as.factor(PAT), type = as.factor(type), field = as.factor(field), wind = as.factor(wind))
k.fit <- glm(good ~ ., family = binomial(link = logit), data = placekick)
summary(k.fit)
Anova(k.fit)
library(dplyr)
placekick <- read.csv("U:/stat475/assignment2/Placekick.csv")
placekick <- mutate(placekick, week = as.factor(week), change = as.factor(change), PAT = as.factor(PAT), type = as.factor(type), field = as.factor(field), wind = as.factor(wind))
k.fit <- glm(good ~ ., family = binomial(link = logit), data = placekick)
summary(k.fit)
Anova(k.fit)
